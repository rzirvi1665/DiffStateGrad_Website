<html lang="en-GB">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Diffusion State-Guided Projected Gradient for Inverse Problems</title>
    <meta name="description" content="We've presented Clarity, a minimalist and elegant website template for AI research.">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <meta name="robots" content="all">
    <meta content="en_EN" property="og:locale">
    <meta content="website" property="og:type">
    <meta content="https://shikun.io/projects/clarity" property="og:url">
    <meta content="Clarity" property="og:title">
    <meta content="Website Template for AI Research" property="og:description">

    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@your_twitter_id">
    <meta name="twitter:description" content="Clarity: A Minimalist Website Template for AI Research">
    <meta name="twitter:image:src" content="assets/figures/clarity.png">
    
    <link rel="stylesheet" type="text/css" media="all" href="assets/stylesheets/main_free.css" />
    <link rel="stylesheet" type="text/css" media="all" href="clarity/clarity.css" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/foundation.min.css">
    <link href="assets/fontawesome-free-6.6.0-web/css/all.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/img-comparison-slider@8/dist/styles.css"/>
    <script defer src="https://cdn.jsdelivr.net/npm/img-comparison-slider@8/dist/index.js"></script>
    <script src="assets/scripts/navbar.js"></script>  <!-- Comment to remove table of content. -->
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            "HTML-CSS": {
              scale: 95,
              fonts: ["Gyre-Pagella"],
              imageFont: null,
              undefinedFamily: "'Arial Unicode MS', cmbright"
            },
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                processEscapes: true
              }
          });
    </script>
    <script type="text/javascript"
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
</head>

<body>
    <!-- Title Page -->
    <!-- Dark Theme Example: Change the background colour dark and change the following div "blog-title" into "blog-title white". -->
    <div class="container blog" id="first-content" style="background-color: #E0E4E6;">
    <!-- If you don't have a project cover: Change "blog-title" into "blog-title no-cover"  -->
    <div class="blog-title no-cover">
        <div class="blog-intro">
            <div>
                <h1 class="title">Diffusion State-Guided Projected Gradient for Inverse Problems</h1>
                <p class="author">
                    Rayhan Zirvi <sup>*1</sup>, Bahareh Tolooshams <sup>*1</sup>, and Anima Anandkumar <sup>1</sup>
                </p>
                <p class="author" style="font-size: smaller; padding-top: 0px;">
                    <sup>*</sup> Equal contribution
                </p>
                <p class="author" style="padding-top: 0px;">
                    <sup>1</sup> Computing and Mathematical Sciences, California Institute of Technology
                </p>
                <p class="abstract">
                    Recent advancements in diffusion models have been effective in learning data priors for solving inverse problems. They leverage diffusion sampling steps for inducing a data prior while using a measurement guidance gradient at each step to impose data consistency. For general inverse problems, approximations are needed when an unconditionally trained diffusion model is used since the measurement likelihood is intractable, leading to inaccurate posterior sampling. In other words, due to their approximations, these methods fail to preserve the generation process on the data manifold defined by the diffusion prior, leading to artifacts in applications such as image restoration. To enhance the performance and robustness of diffusion models in solving inverse problems, we propose <i>Diffusion State-Guided Projected Gradient</i> (DiffStateGrad), which projects the measurement gradient onto a subspace that is a low-rank approximation of an intermediate state of the diffusion process. DiffStateGrad, as a module, can be added to a wide range of diffusion-based inverse solvers to improve the preservation of the diffusion process on the prior manifold and filter out artifact-inducing components. We highlight that DiffStateGrad improves the robustness of diffusion models in terms of the choice of measurement guidance step size and noise while improving the worstcase performance. Finally, we demonstrate that DiffStateGrad improves upon the state-of-the-art on linear and nonlinear image restoration inverse problems.
                </p>
                <!-- Using FontAwesome Free -->
                <div class="info">
                    <div>
                        <a href="https://arxiv.org/abs/2410.03463" class="button icon" style="background-color: rgba(255, 255, 255, 0.2)"> Paper <i class="fa-solid fa-book-open"></i></a> &nbsp;&nbsp; 
                        <a href="https://github.com" class="button icon" style="background-color: rgba(255, 255, 255, 0.2)">Code <i class="fa-solid fa-code"></i></a>  &nbsp;&nbsp; 
                    </div>
                </div>
            </div>
           
            <div class="info">
                <p>ICLR 2025</p>
            </div>
        </div>
    </div>
</div>


    <div class="container blog main first" id="blog-main">
        <h1>
            Introduction
        </h1>
        <p class='text'>
            Inverse problems are ubiquitous in science and engineering, playing a crucial role in simulation-based scientific discovery and real-world applications. These problems arise in fields ranging from medical imaging and remote sensing to astrophysics and computational neuroscience. At their core, inverse problems aim to recover an unknown signal from noisy observations, where the measurement process may be incomplete or degraded.
        </p>
        <p class="text">
            Traditional approaches have relied on sparse priors, providing theoretical guarantees for unique data recovery. More recent approaches leverage information directly from data, with state-of-the-art techniques employing generative diffusion models. Despite their impressive capabilities, diffusion models face significant challenges in solving inverse problems. The primary difficulty stems from the intractability of the posterior distribution when using unconditionally trained models. These approximations often lead to inaccurate sampling and artifacts in reconstructed data. Furthermore, current diffusion-based approaches lack robustness to parameters such as gradient step size and measurement noise, limiting their practical utility in real-world applications.
        </p>
    </div>

    <div class="container blog main gray">
        <img src="clarity/images/manifold_diffstategrad.png">
        <p class="caption">
            DiffStateGrad projects the measurement gradient onto a subspace defined to capture statistics of the diffusion state at time t on which the gradient guidance is applied. This helps the process stay closer to the data manifold during the diffusion process, resulting in better posterior sampling. Without such projection, the measurement gradient pushes the process off the data manifold.
        </p>
    </div>

    <div class="container blog main">
        <h1>Our Contributions</h1>
        <p class="text">
            We propose a <i>Diffusion State-Guided Projected Gradient</i> (DiffStateGrad) to address the challenge of staying on the data manifold in solving inverse problems. We focus on gradient-based measurement guidance approaches that use the measurement as guidance to move the intermediate diffusion state toward high-probability regions of the posterior. DiffStateGrad projects the measurement guidance gradient onto a low-rank subspace, capturing the data statistics of the learned prior. We define a projection step to preserve the measurement gradient on the tangent space of the state manifold. We achieve this projection by performing singular value decomposition (SVD) on the diffusion state of an image to which guidance is applied and use the highest contributing singular vectors as our projection matrix.
        </p>
        <p class="text">
    Our key contributions include:
    </p>
    <p class="text">
        • Showing that the crucial factor is the choice of the subspace, not just its low-rank nature
    </p>
    <p class="text">
        • Theoretically proving how DiffStateGrad helps samples remain on or close to the manifold, improving reconstruction quality
    </p>
    <p class="text">
        • Increasing the robustness of diffusion models to measurement guidance gradient step size and measurement noise, with dramatic improvements in metrics across various tasks
    </p>
    <p class="text">
        • Improving metrics significantly - for example, DiffStateGrad reduces the LPIPS of PSLD from 0.463 to 0.165 on random inpainting with large step sizes
    </p>
    <p class="text">
        • Empirically demonstrating that DiffStateGrad significantly improves worst-case performance, reducing the failure rate from 26% to 4% on phase retrieval tasks
    </p>
    <p class="text">
        • Consistently showing lower standard deviation than state-of-the-art methods
    </p>
</div>

    <div class="container blog main gray">
        <img src="clarity/images/psnr_histogram_improved (1).png">
        <p class="caption">
            DiffStateGrad improves worst-case performance.
        </p>
    </div>

    <div class="container blog main">
        <h1>Results</h1>
        <h2>Robustness</h2>
        <p class="text">
            DiffStateGrad significantly improves the robustness of diffusion models to various factors. Our experiments show that while conventional methods deteriorate when measurement gradient step size increases, DiffStateGrad maintains high performance across a wide range of step sizes. Similarly, when faced with increasing measurement noise, DiffStateGrad exhibits superior resilience compared to standard methods, which experience substantial performance degradation.
        </p>
    </div>

    <div class="container blog main gray">
    <img src="clarity/images/step_size_robus.png">
        <p class="caption">
            DiffStateGrad improves robustness to measurement gradient (MG) step size.
        </p>
    </div>

        
    <div class="container blog main gray">
    <img src="clarity/images/noise_robust.png">
        <p class="caption">
            DiffStateGrad improves robustness to measurement noise.
        </p>
    </div>

    <div class="container blog main">
        <h2>Performance</h2>
    <p class="text">
        Our quantitative and qualitative results demonstrate substantial improvement in performance across a variety of linear and nonlinear tasks. DiffStateGrad enhances both pixel-based and latent solvers, with particularly impressive gains in challenging tasks like phase retrieval and high dynamic range reconstruction. For example, when applied to ReSample for phase retrieval, DiffStateGrad improves PSNR from 27.61 to 31.19 while reducing standard deviation from 8.07 to 4.33, indicating both better and more consistent performance.
    </p>
</div>

<div class="container blog main gray">
        <img src="clarity/images/psld_comp.png">
        <p class="caption">
            DiffStateGrad removes artifacts and reduces failure cases, producing more reliable reconstructions.
        </p>
    </div>

<div class="container blog main gray">
        <img src="clarity/images/phase_example (1).png">
        <p class="caption">
            DiffStateGrad produces consistent reconstructions in challenging non-linear tasks such as phase retrieval.
        </p>
    </div>

<div class="container blog main">
    <h1>Citation</h1>
    <p class="text">
        If you find our work interesting, please consider citing
    </p>
<pre><code class="plaintext">@inproceedings{zirvi2025diffusion,
    title={Diffusion State-Guided Projected Gradient for Inverse Problems},
    author={Rayhan Zirvi and Bahareh Tolooshams and Anima Anandkumar},
    booktitle={The Thirteenth International Conference on Learning Representations},
    year={2025}
}</code></pre>
    </div>

    <!-- Footer Page -->
    <footer>
        <div class="container">
            <p>
                This website is built on the <a href="https://shikun.io/projects/clarity">Clarity Template</a>, designed by <a href="https://shikun.io/">Shikun Liu</a>.
            </p>
        </div>    
    </footer>
    

    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
    <script src="clarity/clarity.js"></script>    
    <script src="assets/scripts/main.js"></script>    
    </html>
</body>
